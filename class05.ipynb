{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第五讲 卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 全连接网络回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 CNN 经典网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 LeNet\n",
    "借鉴点：共享卷积核，减少网络参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 AlexNet\n",
    "\n",
    "借鉴点：激活函数使用 Relu，提升训练速度；Dropout 防止过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 VGGNet\n",
    "借鉴点：小卷积核减少参数的同时，提高识别准确率；网络结构规整，适合并行加速。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.4 InceptionNet\n",
    "借鉴点：一层内使用不同尺寸的卷积核，提升感知力（通过 padding 实现输出特征面积一致）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.5 ResNet\n",
    "\n",
    "借鉴点：层间残差跳连，引入前方信息，减少梯度消失，使神经网络层数变身成为可能。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
